## Java基础

Java 中的JVM针对不同系统的特定实现，目的是使相同的字节码在不同系统中会给出相同的结果

字节码：JVM可以理解的代码就是字节码（.class文件），不面向任何特定处理器，只面向虚拟机。在一定程度上解决了传统解释型语言**执行效率低的问题**，同时保留了**可移植**的特点。

JRE：Java运行时环境，包括JVM，Java类库，Java命令和其他的一些基础构件，不能用于创建新程序

JDK：Java开发工具。拥有除了JRE的一切以外，还有编译器javac和工具（例如javadoc和jdb）。能够创建和编译程序



### JAVA和C++的异同

1. 都是面向对象的，都支持封装，继承，多态
2. Java不提供指针来访问内存，程序内存更加安全
3. Java类是单继承，C++多继承，但是Java的接口是多继承的
4. Java有自动内存管理机制，不需要程序员手动释放无用内容
5. 在C语言中，字符串或字符数组最后都会有一个额外的字符'\0'来表示结束，但是Java没这个概念



### 无参不做事构造方法的作用

Java程序在执行子类构造方法之前，如果没有`super()`来调用父类特定的构造方法，则会调用父类中没有参数的构造方法，所以如果父类中没有这个无参构造方法，会报错。



### hashCode和equals

1) hashCode()的作用是获取哈希码，即散列码，实际上是返回一个int整数。这个哈希码的作用是确定对象在哈希表中的索引位置。Java中这个方法是放在Object类中的，所以任何类都有。同时这个方法是本地方法，是用C或者C++实现的。
2) hashCode的作用是利用哈希值进行更快的第一次判断，筛选掉哈希值不同的对象，当哈希值相同时再用equals()判断，这样减少了equals()的使用次数，提高了执行速度
3) 两个对象相等，那么哈希值也一定相同，equals()会返回true；但是如果两个对象哈希值相同，它们并不一定相等，所以重写`equals()`时需要重写`hashCode()`





### 线程、程序和进程

**程序**是含有指令的数据和文件，存储在数据存储设备中，也就是说程序是静态的代码。

**进程**是程序一次执行过程，是系统运行程序的基本单位，是动态的。

**线程**是进程划分成的更小的运行单位。进程是独立的，而线程不一定，同一个进程中的线程极有可能会相互影响。

### 线程的基本状态

![image-20211220164342351](/Users/yangmao/Library/Application Support/typora-user-images/image-20211220164342351.png)

![image-20211220163630971](/Users/yangmao/Library/Application Support/typora-user-images/image-20211220163630971.png)

线程创建之后它将处于 **NEW（新建）** 状态，调⽤ ` start()`  ⽅法后开始运⾏，线程这时候处于 **READY（可运⾏） **状态。可运⾏状态的线程获得了 cpu 时间⽚（timeslice）后就处于 **RUNNING（运⾏）** 状态。

### transient关键字作用

阻止实例中那些用此关键字修饰的变量序列化；当对象被反序列化时，被transient修饰的变量值不会被持久化和恢复。transient只能修饰变量，不能修饰类和方法

## Java中的IO流

按操作方式分

![image-20211220170210460](/Users/yangmao/Library/Application Support/typora-user-images/image-20211220170210460.png)

按操作对象分

![image-20211220170252800](/Users/yangmao/Library/Application Support/typora-user-images/image-20211220170252800.png)

有了字节流为什么还要字符流？（不管文件读写还是网络收发，信息的最小存储单元都是字节，为什么IO流操作要分为字节流操作和字符流操作？）

字符流是由Java虚拟机将字节转换得到的，这个转化过程非常耗时，并且如果我们不知道编码类型容易出现乱码，所以IO流提供了一个直接操作字符的接口，方便对字符进行操作。如果是音频、图片等媒体文件则用字节流比较好，而文字还是字符流比较好。

### BIO,NIO,AIO的区别

* BIO (Blocking I/O): 同步阻塞 I/O 模式，数据的读取写⼊必须阻塞在⼀个线程内等待其完
  成。在活动连接数不是特别⾼（⼩于单机 1000）的情况下，这种模型是⽐较不错的，可以让每⼀个连接专注于⾃⼰的 I/O 并且编程模型简单，也不⽤过多考虑系统的过载、限流等问题。线程池本身就是⼀个天然的漏⽃，可以缓冲⼀些系统处理不了的连接或请求。但是，当⾯对⼗万甚⾄百万级连接的时候，传统的 BIO 模型是⽆能为⼒的。因此，我们需要⼀种更⾼效的 I/O 处理模型来应对更⾼的并发量

* NIO (Non-blocking/New I/O): NIO 是⼀种同步⾮阻塞的 I/O 模型，在 Java 1.4 中引⼊了
  NIO 框架，对应 java.nio 包，提供了 Channel , Selector，Buffer 等抽象。NIO 中的 N 可以理解为 Non-blocking，不单纯是 New。它⽀持⾯向缓冲的，基于通道的 I/O 操作⽅法。NIO 提供了与传统 BIO 模型中的  Socket  和  ServerSocket  相对应的  SocketChannel  和ServerSocketChannel  两种不同的套接字通道实现,两种通道都⽀持阻塞和⾮阻塞两种模式。阻塞模式使⽤就像传统中的⽀持⼀样，⽐较简单，但是性能和可靠性都不好；⾮阻塞模式正 好与之相反。对于低负载、低并发的应⽤程序，可以使⽤同步阻塞 I/O 来提升开发速率和更 好的维护性；对于⾼负载、⾼并发的（⽹络）应⽤，应使⽤ NIO 的⾮阻塞模式来开发

* AIO (Asynchronous I/O): AIO 也就是 NIO 2。在 Java 7 中引⼊了 NIO 的改进版 NIO 2,它 是异步⾮阻塞的 IO 模型。异步 IO 是基于事件和回调机制实现的，也就是应⽤操作之后会直 接返回，不会堵塞在那⾥，当后台处理完成，操作系统会通知相应的线程进⾏后续的操作。 AIO 是异步 IO 的缩写，虽然 NIO 在⽹络操作中，提供了⾮阻塞的⽅法，但是 NIO 的 IO ⾏ 为还是同步的。对于 NIO 来说，我们的业务线程是在 IO 操作准备好时，得到通知，接着就 由这个线程⾃⾏进⾏ IO 操作，IO 操作本身是同步的。查阅⽹上相关资料，我发现就⽬前来 说 AIO 的应⽤还不是很⼴泛，Netty 之前也尝试使⽤过 AIO，不过⼜放弃了。

### 深拷贝和浅拷贝

1. 深拷贝：对基本数据类型进行值传递，对引用数据类型创建一个新的对象，并复制其内容
2. 浅拷贝：对基本数据类型进行值传递，对引用数据类型进行引用传递般的拷贝

## Java集合

### ArrayList和LinkedList的异同

1. 线程安全性：都不同步，都不安全
2. 底层数据结构：前者Object数组，后者双向链表
3. 插入和删除是否受元素位置影响：前者在中间插入会有影响，后者无
4. 是否支持快速随机访问：前者支持，后者不支持
5. 内存空间占用：前者的占用体现在列表会预留一定的空间，后者在于链表本身每一个元素占空间会比ArrayList多（因为需要存放prev，next和本身的数据

### HashTable和HashMap的区别

1. 线程安全性：前者安全，后者不安全
2. 效率：因为线程问题，HashMap效率高。而HashTable即使线程安全，现在也基本不用了。
3. 对Null Key和Null Value的支持。前者不能有Null的Key或者Value，否则会抛出`NullPointerException`
4. 底层数据结构：在JDK1.8之后，`HashMap`在解决哈希冲突时有了较大变化，当链表长度大于阈值（默认为8）时，（在转换前会先判断，如果当前数组长度小于64，那么先进行数组扩充，而不是转换）将链表转化成红黑树，以减少搜索时间。而HashTable没有这个机制。
5. 初始大小和每次扩充的不同：
   * 创建时不指定初始值，前者为11，每次扩充为原来的`2n+1`，后者默认16，每次扩充扩充为之前的两倍
   * 如果给定初始值，前者使用这个为初始容量，后者会扩充为2的幂次方大小

### HashSet和HashMap

HashSet的底层就是基于HashMap实现的。前者的源码非常少，因为除了`clone(), writeObject(), readObject()`之外，其他都是调用后者的方法

### HashMap多线程死循环问题

在并罚下的Rehash会造成元素之间形成一个循环链表，由此成为了死循环，不过jdk1.8之后解决了这个问题。但是由于多线程情况下，HashMap会存在其他问题比如数据丢失，所以在多线程情况下不用HashMap而用ConcurrentHashMap

### ConcurrentHashMap和HashTable

二者区别主要体现在线程安全实现方式上

* 底层数据结构：前者1.7以前是分段数组+链表，JDK1.8之后和HashMap1.8的一样，数组+链表/红黑二叉树。而后者一直是数组+链表
* **实现线程安全的方式**：
  * 在JDK1.7的时候，ConcurrentHashMap对整个桶数组进行了分割分段（Segment），每一把锁只锁容器其中一部分数据。JDK1.8之后，摒弃了Segment的概念，直接用Node数组+链表+红黑树的数据结构来实现，并发控制使用synchronized和CAS来操作。
  * HashTable：使用synchronized来保证线程安全，效率低下

### HashSet、LinkedHashSet和TreeSet

HashSet是Set主要实现类，底层为HashMap，线程不安全，可以存null值；

LinkedHashSet是HashSet的子类，能够按添加顺序遍历

TreeSet底层使用红黑树，能够按照添加元素顺序进行遍历，排序方式有自然排序和定制排序

## 多线程

线程与进程相似，但是线程是一个比进程更小的执行单位。一个程序在其执行的过程中，可以产生多个线程。与进程不同的是同类的多个线程共享进程的**堆**和**方法区**资源，但是每个线程有独立的**程序计数器、虚拟机栈和本地方法栈**。

### 程序计数器为什么私有

程序计数器作用是通过被字节码解释器的改变来依次读取指令，从而实现代码的流程控制。而在多线程中，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候知道该线程上次运行到那儿了

总之：程序计数器私有是为了**线程切换后能恢复到正确的执行位置**

### 虚拟机栈和本地方法栈为什么私有

为了保证线程中的局部变量不被别的线程访问到

### 并发和并行

并发：同一时间段，多个任务都在执行（单位时间内不一定同时执行）

并行：单位时间内，多个任务同时执行

### 多线程利弊

并发程序的目的是为了提高程序的执行效率提高程序运行速度。

但是存在一些问题，例如：内存泄漏，上下文切换，死锁

### 上下文切换

多线程编程中，一般来说线程个数都会大于CPU核心的个数，同一时刻CPU核心只能被一个线程使用，为了让这些线程都执行，CPU采取的侧落实为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候会重新处于就绪状态让给其它线程使用，这个过程就是一次上下文切换

### 死锁

定义：多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期阻塞，因此程序不可能正常终止。

死锁的四个产生条件：

1. 互斥条件
2. 请求与保持条件
3. 不剥夺条件
4. 循环等待条件

如何避免线程死锁：破坏四个产生条件

1. 破坏互斥条件：这个无法破坏，因为锁的作用就是让资源互斥
2. 破坏请求与保持条件：一次性申请所有的资源
3. 破坏不剥夺条件：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源
4. 破坏循环等待条件：靠按需申请资源来预防。按照某一顺序申请资源，释放资源则反序释放

### sleep()和wait()的异同

* 前者没有释放锁而后者释放锁
* 都可以暂停线程
* 前者通常用于暂停执行而后者用于线程间交互
* 前者暂停线程一定时间后，自动苏醒；而后者必须要notify()或者notifyAll()方法来唤醒

### 为什么直接用start()本质上是执行run()，但是不直接run()

new了一个Thread之后，线程进入了新建状态。调用start()方法，会启动一个线程并使线程进入就绪状态，当分配到时间片后开始运行。然后在start()运行的过程中，自动调用run()方法。但是如果直接调用run()方法，那么程序会把它当做main线程中的一个普通的方法去执行，并不会在某个线程中来执行它，所以就不是多线程工作。

**调用start()方法可启动线程并使线程进入就绪状态，直接run()方法的话不会以多线程方式执行**

### synchronized关键字

synchronized关键字解决的是多个线程之间访问资源的同步性，它可以保证被它修饰的方法或者代码块在任意时刻只有一个线程执行

三个使用方式：

1. 修饰实例方法：作用于当前对象实例加锁，进入同步代码前要获得当前实例的锁
2. 修饰静态方法：也就是给当前类加锁，会作用于类的所有对象实例，进入同步代码前要获得当前class 的锁。如果线程A调用一个实例对象非静态synchronized方法，而B调用的是静态的synchronized方法，是不会冲突的。**因为A线程占用的锁是实例对象锁，而B是当前类的锁**
3. 修饰代码块：指定加锁对象，对给定对象/类加锁。synchronized(this)表示进入同步代码块前要获得给定对象的锁。

单例模式以及双重检验锁方式实现单例模式（懒汉式）的原理

```java
public class Singleton {
  private volatile static Singleton uniqueInstance;
  
  private Singleton(){
  }
  
  public static Singleton getUniqueInstance() {
    if(uniqueInstance == null) {
      synchronized (Singleton.class) {
        if(uniqueInstance == null){
          uniqueInstance = new Singleton();
        }
      }
    }
    return uniqueInstance;
  }
}
```

volatile关键字的作用：

对于`uniqueInstance = new Singleton();`，实际上是三个步骤

1. 为uniqueInstance分配内容空间
2. 初始化uniqueInstance
3. 将uniqueInstance指向分配的内存地址

但是由于JVM的指令重排，顺序可能变成1->3->2，单线程下倒是没问题，但是多线程下可能造成没有初始化实例。使用volatile可以防止JVM指令重排，保证实例创建。

### synchronized关键字和构造方法

构造方法本身是线程安全的，所以构造方法不能被synchronized修饰

### synchronized关键字修饰方法和代码块时的区别

`synchronized`修饰同步语句块的实现使用的是`monitorenter`和`monitorexit`指令，前者指向同步代码块开始的位置，后者指向结束

`synchronized`修饰方法的时候，没有这两个指令，而是`ACC_SYNCHRONIZED`标识，该标识指明了该方法是个同步方法

但是，本质上两者都是对对象监视器monitor的获取

### JMM(Java内存模型)

在JDK1.2之前，Java的内存模型总是从主存读取变量。而在现在的JMM中，线程可以把变量保存本地内存（寄存器）而不是直接主存读写。这就可能造成一个线程在主存中修改了一个变量的值，而另一个线程还在继续使用它的拷贝，造成数据不一致。

这就需要使用volatile，这就指示JVM这个变量是共享且不稳定的，每次使用它都要到主存中进行读取。

所以，volatile关键字作用是防止JVM的指令重排，以及保证变量的可见性。

### synchronized和volatile的区别

二者是互补的，不是对立的，可能同时使用

* volatile是轻量级实现，只能作用于变量，但是性能更好，synchronized可以用于修饰方法以及代码块
* volatile关键字能保证数据的可见性但是不能保证原子性；而synchronized都能保证
* volatile关键字用于解决变量在多个线程之间的可见性，而synchronized解决的是多个线程之间访问资源的同步性

### ThreadLocal的概念，原理及存在的问题

概念：

ThreadLocal类主要解决的是让每个线程绑定自己的值，可以将ThreadLocal类比如成存放数据的盒子，盒子中可以存储每个线程的私有数据。当一个ThreadLocal变量被创建，那么访问这个变量的每个线程都会有这个变量的本地副本。这些线程使用get()和set()方法来获取默认值或者将值改为当前线程所存的副本的值。

原理：

在Thread类中，有一个threadLocals和一个inheritableThreadLocals变量，他们都是ThreadLocalMap类型的变量，这个ThreadLocalMap类似于ThreadLocal类的定制化HashMap。默认下，两个变量都是null，只有调用set()和get()方法才能创建它们。

而调用set()和get()方法实际上是调用的ThreadLocalMap的set()和get()方法。最终的变量是放在了当前线程的ThreadLocalMap中，并不是在ThreadLocal上，ThreadLocal是对ThreadLocalMap的封装，传递了变量的值。

ThreadLocal内部维护类似Map数据结构的ThreadLocalMap，key为当前Thread，值为Object对象

问题：

ThreadLocalMap中的key为ThreadLocal的弱引用，而value是强引用。弱引用在被垃圾回收线程扫描到时，不管内存是否足够，都会清理，所以key在垃圾回收过程中会被清理，而value作为强引用不会，于是ThreadLocalMap中就出现了null为key的Entry，就会造成内存泄漏。所以在ThreadLocal方法后，最好手动调用remove()方法清理。

### 线程池

**池化思想**：无论是线程池、数据库连接池、Http连接池等都是用的这个思想。主要是为了减少每次获取资源的消耗，提高对资源的利用率。

**线程池**：提供了一种限制和资源管理。每个线程池还维护了一些基本统计信息。

好处：

1. **降低资源消耗**
2. **提高响应速度**
3. **提高线程的可管理性**

#### Runnable和Callable

Runnable接口不会返回结果或者抛出检查异常，但是Callable可以。

Executors工具类可以实现二者的转换

#### submit()和execute()

execute()方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功

submit()方法用于提交需要返回值的任务，而在源码上，submit()内部就是调用了execute()，不过返回一个Future类型对象，以此判断是否执行成功。

#### 线程池的创建

1. 利用ThreadPoolExecutor的构造器创建
2. 通过Executor框架工具类Executors创建，该方法可以创建三个类型的线程池（但是阿里巴巴Java开发手册中强制线程池不允许用Executors去创建）：
   * FixedThreadPool 
   * SingleThreadPool
   * CachedThreadPool

ThreadPoolExecutor构造器分析

```java
public ThreadPoolExecutor(int corePoolSize,
                         int maximumPoolSize,
                         long keepAliveTime,
                         TimeUnit unit,
                         BlockingQueue<Runnable> workQueue,
                         ThreadFactory threadFactory,
                         RejectedExecutionHandler handler){
  if(corePoolSize < 0 || 
    maximumPoolSize <=0 || 
    maximumPoolSize < corePoolSize ||
    keepAliveTime < 0)
    throw new IllegalArgumentException();
  if(workQueue==null || threadFactory == null || handler == null)
    throw new NUllPOinterException();
  ······//下面就是赋值环节this.xxxx = xxxx
}
```

参数：

1. **corePoolSize**：核心线程数定义了最小可以同时运行的线程数量

2. **maximumPoolSize**：当前队列存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数

3. **workQueue**：当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中

4. KeepAliveTime：线程池中线程数量大于corePoolSize时，如果这时没有新的任务提交，核心线程外的线程不会立刻销毁，而是等待KeepAliveTime的时间后才销毁

5. unit：KeepAliveTime的单位

6. threadFactory：executor创建新线程时才会用到

7. handler：饱和策略（当同时运行线程达到最大线程且任务队列也放满了的策略）
   * ThreadPoolExecutor.AbortPolicy
   * ThreadPoolExecutor.CallerRunsPolicy
   * ThreadPoolExecutor.DiscardPolicy
   * ThreadPoolExecutor.DiscardOldsetPolicy

![image-20211222161337336](/Users/yangmao/Library/Application Support/typora-user-images/image-20211222161337336.png)

### 原子类

原子类是指一个操作是不可中断的。即使在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。

并发包`java.util.concurrent`的原子类都在`java.util.concurrent.atomic`下

分类：

基本型：AtomicInteger, AtomicLong, AtomicBoolean

数组类型：AtomicIntegerArray, AtomicLongArray, AtomicReferenceArray

引用类型：AtomicReference, AtomicStampedReference, AtomicMarkableReference

对象的属性修改型：AtomicIntegerFieldUpdater, AtomicLongFieldUpdater, AtomicReferenceFieldUpdater

### AQS(AbstractQueuedSynchronizer)

是在JUC包下locks包内。是一个用来构建锁和同步器的框架，使用AQS能简单高效的构造出应用广泛的大量同步器。

原理：

如果被请求的共享资源空闲，则将当前求求资源的线程设置为有效的工作线程，并将共享的资源设置为锁定状态。如果请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。

资源共享方式

1. 独占：只有一个线程能执行
   * 公平锁：先到先得
   * 非公平锁：无视顺序，抢到者得
2. 共享：多个线程可同时执行

组件：

1. Semaphore(信号量)-允许多个线程同时访问：可以指定多个线程同时访问某个资源
2. CountDownLatch(倒计时器)：用来协调多个线程之间的同步
3. CyclicBarrier(循环栅栏)：和2相似，但是更复杂强大

## JVM

### Java内存区域

JDK1.8之前

线程共享：堆，方法区（方法区中包含运行时常量池），直接内存（非运行时的一部分）

线程私有：虚拟机栈，本地方法栈，程序计数器

JDK1.8后，方法区被移除，到了直接内存，变成了元空间

**程序计数器**：是当前线程所执行的字节码的行号指示器。通过改变这个计数器的值来选取下一条需要执行的代码指令。是唯一一个不会出现`OutOfMemoryError`的内存区域，随着线程的创建而创建，随着线程的结束而死亡

**虚拟机栈**

生命周期与线程相同。描述的是Java方法执行的内存模型，每次方法调用的数据都是通过栈传递的。Java内存粗糙区分就是堆和栈，其中栈就是指虚拟机栈，用于存放**局部变量表**。局部变量表蛀牙存放了编译期可知的各种数据类型（基本类型），对象引用。

会出现的两种错误：StackOverFlowError和OutOfMemoryError

OutOfMemoryError：若Java虚拟机堆中没有空闲内存，并且垃圾回收器也无法提供更多内存，就会报此错误

**本地方法栈**：和虚拟机栈类似，但是虚拟机栈为虚拟机执行Java方法（字节码）服务，而本地方法栈为虚拟机使用到的Native方法服务。抛出的错误和虚拟机栈一样

**堆**

是Java虚拟机中最大的一块，Java堆是所有线程共享的。

唯一的目的是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。不是所有对象，是因为随着技术的成熟，栈上分配，标量替换优化技术将会导致一些微秒的变化。

因为是垃圾收集器管理的主要区域所以也被称为GC堆。

在JDK7及以前，堆分为：新生代内存，老生代和永生代

在JDK8以后，方法区（永生代）被彻底移除，取而代之的是元空间，元空间直接使用内存

常见错误OutOfMemoryEroor

**方法区**

是线程共享的内存区域，用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是他叫做Non-Heap。

#### 永久代为什么要替换为元空间

1. JVM对于永久代有设置固定大小上限，无法进行调整，而元空间使用的是直接内存，虽然元空间仍存在移除可能，但是比原来纪律小很多
2. 元空间存放的是类的元数据，这样加载多少类的元数据就不由MaxPermSize控制了，而由系统的实际可用空间来控制，这样可以加载的类就更多了
3. 在JDK8，合并HotSpot和JRockit的代码时，JRockit从来没有一个叫永久代的东西，合并之后没必要额外设置一个。

**运行时常量池**

方法区的一部分。Class文件除了类的版本、字段、方法等信息外，还有常量池表。

因为属于方法区，所以会受到方法区内存限制，常量池无法申请到内存时会抛出OutOfMemoryError

### Java对象的创建过程

1. **类的加载检查**。虚拟机遇到一个new时，首先去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并检查这个符号引用是否已经被加载、解析和初始化过。如果没有，那么就先执行相应的类的加载过程。
2. **分配内存**。类加载检查通过后，虚拟机会给对象分配内存。对象所需要的内存大小在第一步就能确定，所以这一步相当于是把一个确定大小的内存从Java堆中划分出来。
   * 分配的方式有**指针碰撞**和**空闲列表**，选择哪种方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。![image-20211224113655813](/Users/yangmao/Library/Application Support/typora-user-images/image-20211224113655813.png)
   * 创建对象的时候，需要线程安全，虚拟机有两种方式保证。
     * CAS+失败重试：CAS是乐观锁的一种实现方式。每次不加锁而是假设没有冲突二区完成，如果有冲突失败了就重试，直到成功。爱方法可以保证更新操作的原子性
     * TLAB：为每个线程预先在Eden区分配一点内存，JVM在给线程中的对象分配内存时，先在TLAB分配，当对象大于TLAB中剩余内存或者TLAB已经用尽时，再采用上面一种方法分配
3. **初始化零值**：除了对象头外，虚拟机需要将分配到的内存空间都初始化为零值
4. **设置对象头**：一些信息，例如对象是哪个类、如何才能找到类的元数据信息、哈希码、对象的GC分段年代等信息，放入对象头中。
5. **执行init方法**：从虚拟机角度看，前四步完成，新的对象就产生了，单从Java程序角度看，对象创建才刚开始。这一步是将对象按照程序员的意愿进行初始化。

### 对象访问定位的两种方式

1. 句柄：Java堆中会划分出一块内存作为句柄池，栈内的reference中存储的就是对象句柄地址，而句柄中包含了对象实例数据与类型数据格子的具体地址信息。优点在于，在对象被移动时，reference不用变，只用改变句柄。
2. 直接指针：Java堆对象的布局就不需要考虑如何放置访问类型数据相关信息，而reference中存储的是对象的地址。优点在于，快，节省了一次指针定位的时间开销

### JVM内存分配与回收

Java自动内存管理主要针对对象内存的回收与分配。最核心的就是堆的管理

由于采用分代垃圾收集算法，所以Java堆可以细分为：新生代老生代；更细致为：Eden空间，From Survivor， To Survivor（这三个是新生代）、Old Memory（老生代）等。进一步划分可以更好的回收内存，或者更快的分配内存。

大部分情况下，对象会在Eden区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入s0或者s1，并且对象的年龄还会加1，当年龄达到一定程度（默认15），就会到老年代。阈值可以通过`-XX:MaxTenuringThreshold`设置。而Hotspot遍历所有对象时，按照年龄从小到大对其所占用大小累积，当累积年龄超过了survivor区一半时，取这个年龄和`MaxTenuringThreshold`中更小的一个座位新的年龄阈值。

经过这次GC后，Eden区和From区被清空。然后From区和To会交换角色，新的To就是上次的From，以保证To的Survivor区域是空的。Minor GC会一直重复这个过程，知道To区被填满，To区填满之后，会将所有移动到老年代去。

### 堆内存中对象的分配基本策略

#### 对象优先在Eden区分派

大多数情况下，对象在新生代中Eden区进行分配，当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC。

在Eden区满内存的情况下，有新的对象生成需要内存，虚拟机进行一次Minor GC，又发现GC中，之前的对象无法存入Survivor空间，所以只好通过**分配担保机制**把新生代的对象提前放入老年代，然后如果新对象能放在新生代中，就放入Eden区。

#### 大对象直接进入老年区

这么做是为了避免大对象分配时由于分配担保机制带来的复制而降低效率。

大对象是需要大量连续内存空间的对象（数组，字符串）

#### 长期存活的对象将进入老年区

对象在Eden出生并经过第一次Minor GC后仍然存货，且能放入Survivor的话，就会被移动到Survivor空间，并将年龄设置为1，之后每经过一次Minor GC，年龄就增长1，一直增长到某个阈值（默认15，可以通过改变MaxTenuringThreshold来改变），之后被放入老年代。

### 如何判断对象是否死亡

1. 引用计数法：给对象添加引用计数器，每有一个地方引用它，计数器就加1，引用失效就减1，任何时候计数器为0的对象就不能再被使用
2. 可达性分析法：通过一系列称为GC Roots的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链的话，对象不可用。

### 强引用、软引用、弱引用和虚引用

1. 强引用：是最普遍的引用。有强引用的对象，垃圾回收器绝对不会回收它，空间不足时，即使是抛出错误，也不可以随意回收强引用的对象来解决内存不足。
2. 软引用：属于可有可无。可以用来实现内存敏感的高速缓存。如果内存够，则不回收，内存不够则回收。
3. 弱引用：同样可有可无。与软引用的区别在于，只具有弱引用的对象拥有更短的生命周期。不管内存够不够，都会回收。但是因为垃圾回收器的优先级很低，因此不一定能及时发现弱引用对象。
4. 虚引用：形同虚设。和没有引用一样，在任何时候都可能被回收。主要用来追踪对象被垃圾回收的活动。

### 回收运行时常量池和方法区

运行时常量池回收的飞起的常量。常量池中的常量，没有任何对象引用它的话，就会被清理。

方法区主要回收无用的类。而无用的类满足以下三点：

1. 该类所有实例已经被回收
2. 加载该类的`ClassLoader`被回收
3. 该类对应的`java.lang.Class`对象没有被任何地方引用，无法在任何地方通过反射访问该类的方法

### 垃圾回收的算法和特点

#### 标记-清除算法

首先标记出所有不需要回收的对象，标记完成后统一回收没被标记的对象。这是最基础的算法，后续算法都是对其不足的改进得到。该算法的两个问题

1. 效率问题
2. 空间问题（标记清楚后会产生大量不连续的碎片）

#### 复制算法

为了解决效率问题诞生的算法。可以将内存分为大小相同的两块，每次使用其中的一块，将存活的对象复制到另一块去，然后再把使用的空间一次清理掉。

#### 标记-整理算法

根据老年代特点提出的标记算法，标记过程和标记-清除一样，但是后续不是直接回收可回收对象，而是让所有存活的对象向一端移动，然后直接清理掉便捷以外的内存

#### 分代收集算法

目前虚拟机采用的算法。算法思想是根据对象存活周期的不同将内存分为几块，一般分为新生代和老年代，根据不同的年代选出适合的算法。

新生代：每次收集都会有大量对象死去，所以选择复制算法。

老年代：对象存活几率高，而且没有额外的空间对它进行分配担保，所以选择标记-清除或者标记-整理进行收集。

**为什么HotSpot要分为新生代和老年代**

由分代收集算法可知，主要是为了提升GC效率。

### 常见垃圾回收器

在下列收集器中，并没有一个最好的收集器。在不同的场景有不同的适合的收集器。

#### Serial收集器

Serial（串行）收集器是最基本、历史最悠久的收集器。是单线程收集器，只会用一条垃圾收集器线程去完成收集工作，在它进行垃圾收集工作的时候必须暂停其他所有的工作线程，直到它收集结束。

新生代采用复制算法，老年代用标记-整理算法。

优点在于简单且高效。

#### ParNew收集器

实际上ParNew收集器就是Serial收集器的多线程版，除了采用多线程收集外，其他和Serial收集器完全一样。

新生代采用复制算法，老年代用标记-整理算法。

Server模式下的虚拟机首要选择，除了Serial只有它能和CMS收集器配合。

并行和并发的区别：

**并行**：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态

**并发**：指用户线程与垃圾收集线程同时执行（但不一定并行），用户程序在继续运行，而垃圾收集器在另一个CPU上

#### Parallel Scavenge收集器

看上去和ParNew一样。特点在于，关注点是吞吐量（高效率的利用CPU），所谓吞吐量是CPU中用于运行用户代码的时间与CPU总时间的比值。

新生代采用复制算法，老年代用标记-整理算法。

#### Serial Old收集器

Serial收集器的老年代版本。一种用途是在JDK1.5以及以前的版本与Parallel Scavenge收集器搭配，另一个是作为CMS的后备方案。

#### Parallel Old收集器

Parallel Scavenge的老年代版本。

#### CMS收集器

Concurrent Mark Sweep收集器是一种以获取最短回收停顿时间为目标的收集器。是HotSpot虚拟机上第一款真正意义上的并发收集器，第一次实现了让垃圾收集线程和用户线程同时工作。

从名字可知，CMS是标记-清除算法实现，整个过程四个步骤

* 初始标记：暂停其他所有的线程，记录与root相连的对象，很快
* 并发标记：同时开启GC和用户线程，用一个闭包去记录可达对象。但是结束时不能保证包含所有可达对象，因为用户线程可能不断的更新引用域，所以GC线程无法保证可达性分析的实时性，所以会跟踪记录这些发生引用更新的地方
* 重新标记：为了修正并发标记中变动的那部分。会停顿比初始标记稍长的时间，但是比并发标记要短
* 并发清除：开启用户线程，同时GC线程开始对未标记的区域做清扫

优点：并发收集、低停顿

缺点：对CPU资源敏感，无法处理浮动垃圾，采用标记-清除算法，回收后会造成大量的空间碎片

#### G1收集器

Garbage-First是一款面向服务器的垃圾收集器，主要针对配备多颗处理器及大容量内存的机器。以极高效率满足GC停顿时间要求的同时，还具备高吞吐量性能特征。

优点：

1. 并行与并发
2. 分代收集
3. 从整体上来看采用标记-整理，从局部上是基于复制
4. 可预测停顿

步骤：

1. 初始标记 
2. 并发标记
3. 最终标记
4. 筛选回收

G1收集器在后台维护一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的部分。

#### ZGC收集器

采用标记-复制算法，不过做了改进，使得Stop The World的情况更少了。
