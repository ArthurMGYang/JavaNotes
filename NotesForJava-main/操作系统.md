# 操作系统

## 什么是操作系统

1. 是管理计算机硬件与软件资源的程序，是计算机的基石
2. 本质上是一个运行在计算机上的软件程序，用于管理计算机硬件和软件资源
3. 操作系统的存在屏蔽了硬件层的复杂性
4. 操作系统的内核(Kernel)是操作系统的核心部分，它负责系统的内存管理，硬件设备的管理，文件系统的管理以及应用程序的管理

## 系统调用

进程在系统上运行有两个级别：

1. 用户态：用户态运行的进程或程序可以直接读取用户程序的数据
2. 系统态：系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制

在运行用户程序中，凡是需要系统态级别的资源有关的操作，都必须通过系统调用的方式向操作系统提出服务请求，并由操作系统代为完成。

系统调用大致为下列几类：

* 设备管理
* 文件管理
* 进程控制
* 进程通信
* 内存管理

## 进程和线程

### 进程和线程的区别

线程是进程划分成的更小的运行单位，一个进程在其执行的过程中可以产生多个线程。更重要的，进程是独立的，而线程则不一定，因为同一进程中的线程极有可能会相互影响。线程开销小，但是不利于资源的管理和保护，进程相反。

### 进程的几种状态

1. 创建状态
2. 就绪状态
3. 运行状态
4. 阻塞状态
5. 结束状态

### 进程间的通信方式

1. 管道/匿名通信(Pipes)：用于具有亲缘关系的父子进程间或兄弟进程间的通信
2. 有名管道(Names Pipes)：遵循先进先出。以磁盘文件的方式存在，可以实现本机任意两个进程通信
3. 信号(Signal)：比较复杂，用于通知接收进程某个事件已经发生
4. 消息队列(Message Queuing):存放在内存中。先进先出。只有内核重启（操作系统重启）或者显示的删除消息队列，该消息队列才会真正的被删除。**消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点**
5. 信号量(Semaphores)：是一个计数器，用于多进程对共享数据的访问
6. 共享内存(Shared Memory)：使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，是最有用的进程间通信方式
7. 套接字(Sockets)：用于客户端和服务器之间通过网络进行通信。

### 线程间的同步方式

1. 互斥量：只有拥有互斥对象的线程才有访问公共资源的权限
2. 信号量：允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问资源的最大线程数
3. 事件：通过通知操作(Wait/Notify)来保持多线程同步

### 进程的调度算法

算法作用：为了确定首先执行哪个进程以及最后执行哪个进程以实现最大CPU利用率

算法：

1. **先到先得服务调度算法(FCFS)**：从就绪队列中选择最先进入的进程为之分配资源，使它立即执行直到结束或因为阻塞放弃CPU占用
2. **短作业优先调度算法(SJF)**：从就绪队列中选择运行时间最短的进程为之分配资源，使它立即执行直到结束或因为阻塞放弃CPU占用
3. **时间片轮转调度算法**：最古老，最简单，最公平且使用最广。每个进程分配一个时间片，即该进程允许运行的时间
4. **多级反馈队列调度算法**：既能使高优先级作业得到响应，又能使短作业进程迅速完成。被公认的一种较好的进程调度算法，UNIX就是使用这个算法
5. **优先级调度**：为每个流程分配优先级，首先执行具有最高优先级的进程，以此类推。

## 操作系统内存管理基础

### 内存管理主要做什么

1. 主要负责内存的分配和回收(`malloc`函数用于申请内存，`free`函数用于释放内存)
2. 地址转换（即将逻辑地址转换成相应的物理地址）等功能

### 常见内存管理机制

简单分为：连续分配管理方式和非连续分配管理方式。

连续分配管理方式指为一个用户程序分配一个连续的内存空间，常见块式管理

非连续分配管理方式允许一个程序使用的内存分布在离散的或者不相邻的内存中，常见页式管理和段式管理

1. **块式管理**：远古时代计算机内存管理方式。将内存分为固定大小块，每个块放一个进程。如果进程只需要很小内存，那么很大一部分就被浪费了，未被利用的部分被称为碎片
2. **页式管理**：把主存分为大小相等且固定的一页一页的形式，页较小，相对于块式管理提高了利用率减少了碎片
3. **段式管理**：把主存分为一段一段，每一段的空间比页更小。页式管理中页没有实际意义，而段是有的，每个段定义了一组逻辑信息
4. **段页式管理**：结合了2，3的优点。把主存分为若干段，每个段又分为若干页，这样段和段之间，段的内部，都是离散的

### 快表和多级页表

页式管理有两个问题需要解决

1. 虚拟地址到物理地址的转换要快
2. 解决虚拟地址空间大，页表也会很大的问题

#### 快表

用于解决上述1问题，可以理解为一种特殊的告诉缓冲存储器Cache，其中的内容是页表的一部分或者全部部分，作为页表的Cache，它的作用与页表相似，但是访问效率高。

转换流程

1. 根据虚拟地址中的页号查快表
2. 如果页在快表中，直接从快表中读取相应的物理地址
3. 如果不在，就访问内存中的页表，再从页表中获取物理地址，同时将页表中该映射添加到快表
4. 当快表填满后，又要登记新页时，就按照一定的策略淘汰快表中的一个页

#### 多级页表

主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。

### 分页机制和分段机制的异同

1. 共同点：
   * 二者都是为了提高内存利用率，减少内存碎片
   * 二者都是离散存储的，都是离散分配内存方式。但是页和段中的内存是连续的
2. 区别：
   * 页的大小是固定的，由操作系统决定；段的大小不固定，由当前运行程序决定
   * 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息单位，在程序中可以体现为代码段，数据段，能够更好的满足用户需求

### 逻辑（虚拟）地址和物理地址

逻辑地址由操作系统决定，也是平时编程打交道的地址，例如C语言的指针存储的数值就是逻辑地址

物理地址是指真实物理内存中地址，也就是内存地址寄存器的地址。

### CPU寻址

CPU寻址即虚拟寻址(Virtual Addressing)。使用虚拟地址，CPU需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。由CPU中被称为**内存管理单元**的硬件实现

### 为什么要有虚拟地址空间

直接访问物理内存存在的问题：

1. 用户程序可以访问人以内存，寻址内存的每个字节，这样容易破坏操作系统，造成操作系统崩溃
2. 想要运行多个程序特别困难

总结：直接把物理地址暴露出来的话会带来严重问题，比如可能对操作系统造成伤害以及给同时运行多个程序造成困难

虚拟地址的优势

1. 程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区
2. 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区
3. 不同进程使用的虚拟地址彼此隔离，一个进程中的代码无法更改正在由另一个进程或者操作系统使用的物理内存

## 虚拟内存

### 什么是虚拟内存

虚拟内存是计算机系统内存管理的一种技术，我们可以手动设置自己电脑的虚拟内存。**虚拟内存定义了一个连续的虚拟地址空间，并且把内存扩展到硬盘空间**

虚拟内存可以让程序可以拥有超过系统物理内存大小的可硬内存空间。另外，虚拟内存为每个进程提供了一个一致的，私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉。

### 局部性原理

局部性原理是虚拟内存技术的基础，正因为程序运行具有局部性原理，CIA可以只装入部分程序到内存就开始运行。

程序在执行的时候往往呈现局部性规律，也就是说在某个较短的时间内，程序执行局限于一小部分，程序访问的存储空间也局限于某个区域。

之局部性原理表现：

1. 时间局限性：程序中某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后可能再次被访问。产生时间局部性的典型原因，是由于程勋中存在着大量的循环操作
2. 空间局限性：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定范围内，这是因为指令通常是顺序存放，顺序执行的，数据一般是以向量，数组，表等形式存储的。

时间局部性通过将近来使用的指令保存到高速缓存存储器中，并使用高速缓存的层次结构实现。

空间局部性使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。

虚拟内存技术实际上是建立了内存——外存的两级存储器结构，利用局部性原理实现高速缓存。

### 虚拟内存的技术实现

三种方式：

1. 请求分页存储管理：建立在分页管理上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。最常用。在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如作业运行中发现内存不足，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统可以将暂时不用的页面置换到外存中。
2. 请求分段存储管理：建立在分段管理上，增加了请求调段功能，分段置换功能。和1类似，作业开始前，仅装入当前要执行的部分段即可运行；执行过程中，可以使用请求调入中断动态装入要访问但不在内存中的程序段；当内存空间满了，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段
3. 请求段页式存储管理

无论是哪种方式，都需要

1. 一定容量的内存和外存
2. 缺页中断：如果需要执行的指令或访问的数据尚未在内存（称为缺页或缺段），则由处理器通过通知系统将相应的页面和段调入内存，然后执行程序
3. 虚拟地址空间

### 页面置换算法

作用：当发生缺页中断时，如果当前内存没有空闲页面，操作系统就必须在内存中选择一个页面将其移除内存，以便为即将调入的页面让出空间。

用来淘汰哪一页的规则就是页面置换算法：

* OPT(Optimal 最佳)页面置换算法：所选择的被淘汰的页面将是以后永不使用的，或者是在最长时间内不再被访问的页面，这样可以保证最低的缺页率。但是由于无法预知这个页面，所以该算法无法实现
* FIFO（先进先出）页面置换算法：总是淘汰最先进入内存的页面，即选择在内存中驻留时间醉酒的页面进行淘汰
* LRU(Least Currently Used最近最久未使用)页面置换算法：赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间T，需要淘汰时，选择页面中T值最大的
* LFU(Least Frequently Used最少使用)页面置换算法：选择在之前时期最少使用的页面作为淘汰页。